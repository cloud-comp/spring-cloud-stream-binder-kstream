== What is this?

This is an example of a Spring Cloud Stream processor using Kafka Streams support.

The example can be run as a standalone application or deployed via Spring Cloud Data Flow.

The example is based on the word count application from the https://github.com/confluentinc/examples/blob/3.2.x/kafka-streams/src/main/java/io/confluent/examples/streams/WordCountLambdaExample.java[reference documentation].
It uses a single input and a single output.

=== Prerequisites

The Spring Cloud Stream Kafka Streams binder must be built following the instructions found link:../../README.adoc[here].

=== Building the project

Build the project:

```
./mvnw clean install
```

Once doing so, the application is available in the local Maven repository.

=== Running standalone

In the standalone running scenario, we will send lines of text using the Kafka console producer, and we will read outbound data using the Kafka console consumer.

First, we will start the application.

[source,bash]
----
java -jar kstream-samples/kstream-word-count/target/kstream-word-count-1.0.0.BUILD-SNAPSHOT.jar  --spring.cloud.stream.bindings.input.destination=words --spring.cloud.stream.bindings.output.destination=counts --spring.profiles.active=standalone
----

The application defines the following properties:

* `spring.cloud.stream.bindings.input.destination` maps the abstract input named `input` of the application to the topic `words`
* `spring.cloud.stream.bindings.output.destination` maps the abstract output named `output` of the application to the topic `counts`
* `spring.profiles.active` activates the `standalone` profile defined in `application.properties`

The `standalone` profile contains a number of properties that allow the application to consume and produce data to non-Spring Cloud Stream applications (such as the console producer/consumer)
By default, Spring Cloud Stream adds metadata such as embedded headers to outbound payloads, which might not be understandable by external applications.
By adding additional configuration properties, that can be turned on/off at launch, the application can be reused either to interact with other Spring Cloud Stream applications, or with other applications that send and receive data to the same topic.

Then start the console producer.

[source,bash]
----
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic words
----

Then start the console consumer

[source,bash]
----
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic counts
----

=== Running in Spring Cloud Data Flow (local)

Download and install the local version Spring Cloud Data Flow.
Import the http and file applications.
A complete set of instructions can be found http://cloud.spring.io/spring-cloud-dataflow/[here].

Register the Kafka Streams Word Count application in the Spring Cloud Data Flow shell.

[source,bash]
----
app register --uri maven://org.springframework.cloud.samples.kstream:kstream-word-count:1.0.0.BUILD-SNAPSHOT --type processor --name kstream-word-count
----

Create the stream:

[source,bash]
----
dataflow:>stream create count-http --definition "http --port=9000 | kstream-word-count | file --directory=/tmp/count-http --name=counts" --deploy
----

Send data:

[source,bash]
----
dataflow:>http post --target http://localhost:9000 --data 'How much wood can a woodchuck chuck if a woodchuck could chuck wood'
----

Monitor the output of the file sink:

[source,bash]
----
tail -f /tmp/count-http/counts
---
